{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_pandas_frame(html, attributes):\n",
    "    '''\n",
    "    Creats a pandas dataframe from a csv like data format from a csv\n",
    "    Also assumes that the header is not in the csv representation nor the index name\n",
    "    :param: html - string for the location of the csv like data on website\n",
    "    :param: attributes - list of strings of the given data set in order\n",
    "    :returns: pandas dataframe\n",
    "    '''\n",
    "    df = pd.read_csv(html, header = None)\n",
    "    df.columns = attributes\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self, eta, iters):\n",
    "        '''\n",
    "        simple constructor function\n",
    "        :param: _iter - int, number of iterations\n",
    "        :param: eta - int, acts as a scalar how much to change weights by\n",
    "        '''\n",
    "        self.eta = eta\n",
    "        self.iters = iters\n",
    "    \n",
    "    def learn(self, row_vectors, output_vectors):\n",
    "        '''\n",
    "        Moves through each row of attributes, and finds a prediction.\n",
    "        Then if necessary, updates the weights to see if \n",
    "        '''\n",
    "        #Generate random number for the length of all rows\n",
    "        generator = np.random.RandomState(1)\n",
    "        \n",
    "        #Because the output_vector and row_vector sizes are equal we just pick one to find size\n",
    "        self.weights = generator.normal(loc=0.0, scale=.01, size = len(row_vectors[0])+1)\n",
    "        for iter in range(self.iters):\n",
    "            error = 0 #initializes error counter to be zero of iter\n",
    "            \n",
    "            for row_vector, output_vector in zip(row_vectors, output_vectors):\n",
    "               \n",
    "                #create a prediction using the weights and given row_vector\n",
    "                prediction = self.predict(row_vector)\n",
    "                error = error + np.where(output_vector == prediction,0,1) \n",
    "                for j in range(len(row_vectors[0])):\n",
    "                    self.weights[j] = self.weights[j] + self.eta * (output_vector - prediction) * row_vector[j]\n",
    "            print(f\"error: {error}, weights {self.weights}\")\n",
    "            \n",
    "    def predict(self, row_vector):\n",
    "        '''\n",
    "        Takes a row_vector and uses dot product across weights, if output is positive\n",
    "        scales the prediction to be 1, else zeros\n",
    "        :param: row_vector - vector, that contains attribute data about single sample\n",
    "        :returns: a prediction as a 1 or -1\n",
    "        '''\n",
    "        input = np.dot(row_vector, self.weights[1:] + self.weights[0])\n",
    "        prediction = np.where(input>=0, 1, -1)\n",
    "        return prediction\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "attributes = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "df = construct_pandas_frame(html, attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.iloc[0:100,[0,2]].values #row vector\n",
    "y = df.iloc[0:100,4].values #output vectors\n",
    "y = np.where(y=='Iris-setosa',1,-1)\n",
    "verify_count = collections.Counter(y) # This is just a quick check we have 50 setosa, 50 not setosa\n",
    "verify_count\n",
    "len(x[0])\n",
    "#model = perceptron(eta = 0.1, iter =10)\n",
    "#model.learn(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 1, weights [-1.38375655 -0.94611756 -0.00528172]\n",
      "error: 3, weights [-0.78375655 -1.32611756 -0.00528172]\n",
      "error: 3, weights [-0.18375655 -1.70611756 -0.00528172]\n",
      "error: 3, weights [ 0.41624345 -2.08611756 -0.00528172]\n",
      "error: 3, weights [ 0.89624345 -2.52611756 -0.00528172]\n",
      "error: 2, weights [ 0.51624345 -3.18611756 -0.00528172]\n",
      "error: 3, weights [ 1.11624345 -3.56611756 -0.00528172]\n",
      "error: 3, weights [ 1.71624345 -3.94611756 -0.00528172]\n",
      "error: 3, weights [ 2.31624345 -4.32611756 -0.00528172]\n",
      "error: 4, weights [  1.81624345e+00  -5.64611756e+00  -5.28171752e-03]\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron(eta= .1, iters = 10)\n",
    "model.learn(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
